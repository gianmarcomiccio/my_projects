{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ae021f-d1e0-4ba5-859a-609a5b687338",
   "metadata": {},
   "source": [
    "# Machine Learning – TDT4173 Group Project \n",
    "### [47] Extreme Machine Learning\n",
    "##### Alessandro Donadi - 133756\n",
    "##### Gian Marco Miccio - 133705\n",
    "##### Giulia Papalini - 133534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7eb57d-cbc4-4ca9-89dd-c2902c1aadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081f05fc-eb24-42b7-872a-0d0378a1aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"ais_train.csv\", delimiter = '|')\n",
    "X_test = pd.read_csv(\"ais_test.csv\", delimiter = ',')\n",
    "ports = pd.read_csv(\"ports.csv\", delimiter = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8dae50f-2516-4d21-8115-272b63205d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74feb8f0-b556-4b4a-af6b-59ec510682f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['cog', 'sog', 'rot', 'heading', 'navstat', 'etaRaw'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c658557-e7cf-4a5f-8ec3-bd26e22fa482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'latitude', 'longitude', 'vesselId', 'portId', 'latitude_port',\n",
      "       'longitude_port'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ports.rename(columns={\n",
    "    'latitude': 'latitude_port',\n",
    "    'longitude': 'longitude_port'\n",
    "}, inplace=True)\n",
    "df = pd.merge(df, ports[['latitude_port', 'longitude_port', 'portId']], on='portId', how='left')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df7b3d2-1af7-4bc9-8b7d-0e99278da8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TIME INTO INT\n",
    "df[\"time\"]=pd.to_datetime(df.time)\n",
    "df['time_int']=df['time'].astype('int64') // 10**9\n",
    "df=df.drop('time', axis=1)\n",
    "\n",
    "\n",
    "# CONVERT TIME INTO INT\n",
    "X_test[\"time\"]=pd.to_datetime(X_test.time)\n",
    "X_test['time_int']=X_test['time'].astype('int64') // 10**9\n",
    "X_test=X_test.drop('time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79973d48-15f0-4ade-897d-73f614243502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>portId</th>\n",
       "      <th>latitude_port</th>\n",
       "      <th>longitude_port</th>\n",
       "      <th>time_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-34.74370</td>\n",
       "      <td>-57.85130</td>\n",
       "      <td>61e9f3a8b937134a3c4bfdf7</td>\n",
       "      <td>61d371c43aeaecc07011a37f</td>\n",
       "      <td>-33.587500</td>\n",
       "      <td>-71.618889</td>\n",
       "      <td>1704067225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.89440</td>\n",
       "      <td>-79.47939</td>\n",
       "      <td>61e9f3d4b937134a3c4bff1f</td>\n",
       "      <td>634c4de270937fc01c3a7689</td>\n",
       "      <td>8.967000</td>\n",
       "      <td>-79.533000</td>\n",
       "      <td>1704067236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.19065</td>\n",
       "      <td>-76.47567</td>\n",
       "      <td>61e9f436b937134a3c4c0131</td>\n",
       "      <td>61d3847bb7b7526e1adf3d19</td>\n",
       "      <td>39.232500</td>\n",
       "      <td>-76.558889</td>\n",
       "      <td>1704067305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.41189</td>\n",
       "      <td>151.02067</td>\n",
       "      <td>61e9f3b4b937134a3c4bfe77</td>\n",
       "      <td>61d36f770a1807568ff9a126</td>\n",
       "      <td>-34.462500</td>\n",
       "      <td>150.899444</td>\n",
       "      <td>1704067391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.88379</td>\n",
       "      <td>-5.91636</td>\n",
       "      <td>61e9f41bb937134a3c4c0087</td>\n",
       "      <td>634c4de270937fc01c3a74f3</td>\n",
       "      <td>35.783000</td>\n",
       "      <td>-5.817000</td>\n",
       "      <td>1704067431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522060</th>\n",
       "      <td>41.33699</td>\n",
       "      <td>2.15130</td>\n",
       "      <td>61e9f3a2b937134a3c4bfdd7</td>\n",
       "      <td>61d37f9c29b60f6113c89e65</td>\n",
       "      <td>41.340278</td>\n",
       "      <td>2.164722</td>\n",
       "      <td>1715126347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522061</th>\n",
       "      <td>49.71372</td>\n",
       "      <td>-5.22042</td>\n",
       "      <td>61e9f43db937134a3c4c0169</td>\n",
       "      <td>634c4de270937fc01c3a787b</td>\n",
       "      <td>50.083000</td>\n",
       "      <td>-5.317000</td>\n",
       "      <td>1715126348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522062</th>\n",
       "      <td>38.27895</td>\n",
       "      <td>10.78280</td>\n",
       "      <td>61e9f469b937134a3c4c029b</td>\n",
       "      <td>61d3781293c6feb83e5eb73b</td>\n",
       "      <td>42.098889</td>\n",
       "      <td>11.780833</td>\n",
       "      <td>1715126348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522063</th>\n",
       "      <td>38.96142</td>\n",
       "      <td>-12.00502</td>\n",
       "      <td>61e9f3aeb937134a3c4bfe43</td>\n",
       "      <td>634c4de270937fc01c3a76a1</td>\n",
       "      <td>38.700000</td>\n",
       "      <td>-9.417000</td>\n",
       "      <td>1715126348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522064</th>\n",
       "      <td>38.98635</td>\n",
       "      <td>-75.13275</td>\n",
       "      <td>62080cff66fc0a8e43c6123a</td>\n",
       "      <td>61d38528b7b7526e1adf3e6f</td>\n",
       "      <td>39.716667</td>\n",
       "      <td>-75.521667</td>\n",
       "      <td>1715126348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1522065 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude  longitude                  vesselId  \\\n",
       "0       -34.74370  -57.85130  61e9f3a8b937134a3c4bfdf7   \n",
       "1         8.89440  -79.47939  61e9f3d4b937134a3c4bff1f   \n",
       "2        39.19065  -76.47567  61e9f436b937134a3c4c0131   \n",
       "3       -34.41189  151.02067  61e9f3b4b937134a3c4bfe77   \n",
       "4        35.88379   -5.91636  61e9f41bb937134a3c4c0087   \n",
       "...           ...        ...                       ...   \n",
       "1522060  41.33699    2.15130  61e9f3a2b937134a3c4bfdd7   \n",
       "1522061  49.71372   -5.22042  61e9f43db937134a3c4c0169   \n",
       "1522062  38.27895   10.78280  61e9f469b937134a3c4c029b   \n",
       "1522063  38.96142  -12.00502  61e9f3aeb937134a3c4bfe43   \n",
       "1522064  38.98635  -75.13275  62080cff66fc0a8e43c6123a   \n",
       "\n",
       "                           portId  latitude_port  longitude_port    time_int  \n",
       "0        61d371c43aeaecc07011a37f     -33.587500      -71.618889  1704067225  \n",
       "1        634c4de270937fc01c3a7689       8.967000      -79.533000  1704067236  \n",
       "2        61d3847bb7b7526e1adf3d19      39.232500      -76.558889  1704067305  \n",
       "3        61d36f770a1807568ff9a126     -34.462500      150.899444  1704067391  \n",
       "4        634c4de270937fc01c3a74f3      35.783000       -5.817000  1704067431  \n",
       "...                           ...            ...             ...         ...  \n",
       "1522060  61d37f9c29b60f6113c89e65      41.340278        2.164722  1715126347  \n",
       "1522061  634c4de270937fc01c3a787b      50.083000       -5.317000  1715126348  \n",
       "1522062  61d3781293c6feb83e5eb73b      42.098889       11.780833  1715126348  \n",
       "1522063  634c4de270937fc01c3a76a1      38.700000       -9.417000  1715126348  \n",
       "1522064  61d38528b7b7526e1adf3e6f      39.716667      -75.521667  1715126348  \n",
       "\n",
       "[1522065 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"time_int\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a6eb93-9e44-4672-9aa2-015dc5d723f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=np.array([1, 55, 72, 99, 124])\n",
    "\n",
    "df['lon_prev'] = df.groupby('vesselId')['longitude'].shift(N[0])\n",
    "df['lat_prev'] = df.groupby('vesselId')['latitude'].shift(N[0])\n",
    "df['time_int_prev'] = df.groupby('vesselId')['time_int'].shift(N[0])\n",
    "df['delta_time'] = df.groupby('vesselId')['time_int'].transform(lambda x: x - x.shift(N[0]))\n",
    "df['lon_prev2'] = df.groupby('vesselId')['longitude'].shift(N[1])\n",
    "df['lat_prev2'] = df.groupby('vesselId')['latitude'].shift(N[1])\n",
    "df['time_int_prev2'] = df.groupby('vesselId')['time_int'].shift(N[1])\n",
    "df['delta_time2'] = df.groupby('vesselId')['time_int'].transform(lambda x: x - x.shift(N[1]))\n",
    "df['lon_prev3'] = df.groupby('vesselId')['longitude'].shift(N[2])\n",
    "df['lat_prev3'] = df.groupby('vesselId')['latitude'].shift(N[2])\n",
    "df['delta_time3'] = df.groupby('vesselId')['time_int'].transform(lambda x: x - x.shift(N[2]))\n",
    "df['lon_prev4'] = df.groupby('vesselId')['longitude'].shift(N[3])\n",
    "df['lat_prev4'] = df.groupby('vesselId')['latitude'].shift(N[3])\n",
    "df['delta_time4'] = df.groupby('vesselId')['time_int'].transform(lambda x: x - x.shift(N[3]))\n",
    "df['lon_prev5'] = df.groupby('vesselId')['longitude'].shift(N[4])\n",
    "df['lat_prev5'] = df.groupby('vesselId')['latitude'].shift(N[4])\n",
    "df['delta_time5'] = df.groupby('vesselId')['time_int'].transform(lambda x: x - x.shift(N[4]))\n",
    "\n",
    "vessel_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "# Fitting e trasformazione delle colonne 'vesselId' e 'portId'\n",
    "df['vesselId_encoded'] = vessel_encoder.fit_transform(df['vesselId'])\n",
    "df = df.drop(columns=['vesselId'])\n",
    "df = df.rename(columns={'vesselId_encoded': 'vesselId'})\n",
    "\n",
    "\n",
    "X_test['vesselId_encoded'] = vessel_encoder.transform(X_test['vesselId'])\n",
    "X_test = X_test.drop(columns=['vesselId'])\n",
    "X_test = X_test.rename(columns={'vesselId_encoded': 'vesselId'})\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "450e0496-214d-4c03-abd4-7f95f0043194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop the nans for portID\n",
    "df.dropna(subset=['portId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42ced32d-5ad0-4be2-a94f-bffd7f92090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('portId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e093164e-1463-496b-9711-076065831a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(model, X_test, df, N):\n",
    "    # Predict latitude and longitude\n",
    "\n",
    "    data = {}\n",
    "    for vessel_id, group in df.groupby('vesselId'):\n",
    "        # Each group becomes a list of tuples (lat_prev, lon_prev, time_int)\n",
    "        data[vessel_id] = list(zip(group['lat_prev'], group['lon_prev'], group['time_int']))\n",
    "\n",
    "    # Initialize the features in the test dataset with NaN\n",
    "    X_test['lat_prev'] = np.nan\n",
    "    X_test['lon_prev'] = np.nan\n",
    "    X_test['delta_time'] = np.nan\n",
    "    X_test['lat_prev2'] = np.nan\n",
    "    X_test['lon_prev2'] = np.nan\n",
    "    X_test['delta_time2'] = np.nan\n",
    "    X_test['lat_prev3'] = np.nan\n",
    "    X_test['lon_prev3'] = np.nan\n",
    "    X_test['delta_time3'] = np.nan\n",
    "    X_test['lat_prev4'] = np.nan\n",
    "    X_test['lon_prev4'] = np.nan\n",
    "    X_test['delta_time4'] = np.nan\n",
    "    X_test['lat_prev5'] = np.nan\n",
    "    X_test['lon_prev5'] = np.nan\n",
    "    X_test['delta_time5'] = np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Dictionary to hold the last known lat/lon for each vessel from the training set\n",
    "    vessel_last_positions = df[['vesselId', 'latitude', 'longitude', 'time_int']].groupby('vesselId').last().to_dict(orient='index')\n",
    "    # Lists to store predictions\n",
    "    predicted_lat = []\n",
    "    predicted_lon = []\n",
    "\n",
    "    total_rows = len(X_test)\n",
    "    increment = total_rows // 10  # Calculate the row count for 10% increments\n",
    "    # Loop through each row in the sorted X_test\n",
    "    for i, row in X_test.iterrows():\n",
    "        if i % increment == 0 and i > 0:\n",
    "           print(f\"Processing: {i / total_rows * 100:.0f}% completed.\")\n",
    "\n",
    "        vessel_id = row['vesselId']\n",
    "\n",
    "        index_offset2 = len(data[vessel_id]) - N[1]\n",
    "        index_offset3 = len(data[vessel_id]) - N[2]\n",
    "        index_offset4 = len(data[vessel_id]) - N[3]\n",
    "        index_offset5 = len(data[vessel_id]) - N[4]\n",
    "        \n",
    "        \n",
    "        # Initialize prev_lat and prev_lon for this vessel\n",
    "        row['lat_prev'] = vessel_last_positions[vessel_id]['latitude']\n",
    "        row['lon_prev'] = vessel_last_positions[vessel_id]['longitude']\n",
    "        row['delta_time'] = row['time_int'] - vessel_last_positions[vessel_id]['time_int']\n",
    "        row['lat_prev2'] = data[vessel_id][index_offset2][0]\n",
    "        row['lon_prev2'] = data[vessel_id][index_offset2][1]\n",
    "        row['delta_time2'] = row['time_int'] - data[vessel_id][index_offset2][2]\n",
    "        row['lat_prev3'] = data[vessel_id][index_offset3][0]\n",
    "        row['lon_prev3'] = data[vessel_id][index_offset3][1]\n",
    "        row['delta_time3'] = row['time_int'] - data[vessel_id][index_offset3][2]\n",
    "        row['lat_prev4'] = data[vessel_id][index_offset4][0]\n",
    "        row['lon_prev4'] = data[vessel_id][index_offset4][1]\n",
    "        row['delta_time4'] = row['time_int'] - data[vessel_id][index_offset4][2]\n",
    "        row['lat_prev5'] = data[vessel_id][index_offset5][0]\n",
    "        row['lon_prev5'] = data[vessel_id][index_offset5][1]\n",
    "        row['delta_time5'] = row['time_int'] - data[vessel_id][index_offset5][2]\n",
    "        \n",
    "        \n",
    "        # Reorder the row to match the feature order expected by the model\n",
    "        row_reordered = row[model.feature_names]  # Ensure correct feature order\n",
    "        row_df = pd.DataFrame([row_reordered], columns=model.feature_names_in_)\n",
    "\n",
    "        # Predict latitude and longitude\n",
    "        pred = model.predict(row_df)\n",
    "        \n",
    "        # Assuming the model outputs a 2D array, where pred[0][0] is latitude and pred[0][1] is longitude\n",
    "        predicted_lat.append(pred[0][0])\n",
    "        predicted_lon.append(pred[0][1])\n",
    "        \n",
    "        # Update prev_latitude and prev_longitude in the vessel_last_positions dictionary\n",
    "        vessel_last_positions[vessel_id] = {'latitude': pred[0][0], 'longitude': pred[0][1], 'time_int': row['time_int']}\n",
    "        data[vessel_id].append((pred[0][0], pred[0][1], row['time_int']))\n",
    "\n",
    "    return predicted_lat, predicted_lon\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09be8e17-6b21-45a9-ae03-ae7b80ada605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['latitude', 'longitude', 'latitude_port', 'longitude_port', 'time_int', 'lon_prev', 'lat_prev', 'time_int_prev', 'delta_time', 'lon_prev2', 'lat_prev2', 'time_int_prev2', 'delta_time2', 'lon_prev3', 'lat_prev3', 'delta_time3', 'lon_prev4', 'lat_prev4', 'delta_time4', 'lon_prev5', 'lat_prev5', 'delta_time5', 'vesselId']\n",
      "['lon_prev', 'lat_prev', 'delta_time', 'lon_prev2', 'lat_prev2', 'delta_time2', 'lon_prev3', 'lat_prev3', 'delta_time3', 'lon_prev4', 'lat_prev4', 'delta_time4', 'lon_prev5', 'lat_prev5', 'delta_time5']\n"
     ]
    }
   ],
   "source": [
    "#creating list of features to use (semi-sutomatically)\n",
    "total_features = df.columns.to_list()\n",
    "print(total_features)\n",
    "y_features = ['latitude', 'longitude'] \n",
    "features_to_remove_from_x = y_features.copy()\n",
    "features_to_remove_from_x.extend(['latitude_port','longitude_port', 'time_int', 'time_int_prev', 'time_int_prev2', 'vesselId']) #if others need to be removed add them here\n",
    "total_features = [feature for feature in total_features if feature not in features_to_remove_from_x]\n",
    "\n",
    "y = df[y_features]\n",
    "print(total_features)\n",
    "X = df[pd.Index(total_features)]\n",
    "\n",
    "Xtrain=X\n",
    "ytrain=y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3088e5a-7242-43d3-acdb-88f5e2882d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_extratrees(X_train, y_train):\n",
    "    # Define the Extra Trees model\n",
    "    et_model = ExtraTreesRegressor(n_jobs =-1, max_depth=80, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=20, random_state = 42, verbose = 0)\n",
    "    \n",
    "    et_model.feature_names = list(X_train.columns.values)  # Save feature names\n",
    "    \n",
    "    et_model.fit(X_train, y_train)\n",
    "    \n",
    "    return et_model\n",
    "\n",
    "        \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a40d1456-4f7b-42d0-8bab-585921b85282",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_model = train_model_extratrees(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41cdd143-2e27-4bf4-b510-c76d02b3aed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 10% completed.\n",
      "Processing: 20% completed.\n",
      "Processing: 30% completed.\n",
      "Processing: 40% completed.\n",
      "Processing: 50% completed.\n",
      "Processing: 60% completed.\n",
      "Processing: 70% completed.\n",
      "Processing: 80% completed.\n",
      "Processing: 90% completed.\n",
      "Processing: 100% completed.\n"
     ]
    }
   ],
   "source": [
    "lat, lon = cycle(et_model, X_test, df, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a4c235-9954-4062-86b0-8edceafb571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the empty file\n",
    "predictions_df = pd.read_csv('ais_sample_submission.csv')\n",
    "\n",
    "#Fill the forecast DataFrame with the latest predictions for longitude and latitude.\n",
    "predictions_df['longitude_predicted'] = pd.DataFrame(lon, columns=['longitude_predicted'])\n",
    "predictions_df['latitude_predicted'] = pd.DataFrame(lat, columns=['latitude_predicted'])\n",
    "\n",
    "#Save the completed file with the forecasts\n",
    "predictions_df.to_csv('predictions_filled_103.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
